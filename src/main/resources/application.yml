# ====== Spring 基本資訊 ======
spring:
  application:
    name: demo
  kafka:
    # 直接覆蓋 Spring 的預設 bootstrap servers（由你自訂 kafka.* 值橋接）
    bootstrap-servers: ${kafka.bootstrap-servers}
    # Producer 預設（可依需要調整）
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
    # Streams（若你使用 Spring Kafka Streams 自動化）
    streams:
      application-id: ${kafka.streams.application-id}
      properties:
        processing.guarantee: ${kafka.streams.properties.processing.guarantee:exactly_once_v2}

server:
  port: 8081

# ====== Mock 開關 ======
mock:
  kafka:
    clickhouse: false
    risk-control: true

# ====== 題目定義（自訂）======
topics:
  events: risk-events
  alerts: risk-alerts

# ====== 自訂 Kafka（作為單一資料源，並橋接到 spring.kafka.*）======
kafka:
  enabled: true
  bootstrap-servers: single-kafka.kafka.orb.local:9092
  streams:
    application-id: hf-risk-custom-buckets
    properties:
      processing.guarantee: exactly_once_v2
  producer:
    records-per-second: 10
    duration-seconds: 5

# ====== Redis（仍採自訂）======
redis:
  enabled: true
  clusterMode: false
  timeout: 2000
  max-attempts: 3
  nodes:
    - redis-single.redis.orb.local:6379

# ====== ClickHouse（自訂）======
clickhouse:
  enabled: false
  url: jdbc:clickhouse://clickhouse.clickhouse.orb.local:8123/default

# ====== RocketMQ（關閉）======
rocketmq:
  enabled: false
  name-server: namesrv.rocketmq.orb.local:9876
  producer:
    group: test-producer-group
    send-message-timeout: 3000
    retry-times-when-send-failed: 2

# ====== Flink（自訂）======
flink:
  enabled: false

# ====== MySQL（自訂）======
datasource:
  enabled: false
  mysql:
    url: jdbc:mysql://mysql.sql.orb.local:3306/testdb
    username: root
    password:
    driver-class-name: com.mysql.cj.jdbc.Driver

# ====== Logging ======
logging:
  level:
    root: INFO
    com.example.demo: INFO
    org.apache.kafka: INFO
    org.apache.flink: INFO
    org.springframework: INFO
    org.springframework.kafka: DEBUG
    org.apache.kafka.streams: INFO
    org.apache.kafka.clients.consumer: INFO
  file:
    name: ${user.dir}/logs/app.log
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
    file:    "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
